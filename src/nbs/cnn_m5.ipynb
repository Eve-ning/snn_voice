{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# M5 Model\n",
    "\n",
    "This notebook **heavily** references the tutorial: *Speech Command Classification with torchaudio*.\n",
    "- [Tutorial](https://pytorch.org/tutorials/intermediate/speech_command_classification_with_torchaudio_tutorial.html)\n",
    "\n",
    "## Derivations\n",
    "We simplified the tutorial by:\n",
    "- Wrapping the PyTorch model in PyTorch-Lightning, abstracting away all low-level nitty-gritty loops\n",
    "- The M5 Model is simplified in code by wrapping common blocks to avoid redundant code: See `cnn_m5.py`\n",
    "- Using PyTorch-Lightning `Trainer`, we limit the number of batches, to make it run quicker\n",
    "\n",
    "## M5 Model Reference\n",
    "[Research Paper](https://arxiv.org/pdf/1610.00087.pdf)\n",
    "Dai, Wei, et al. \"Very deep convolutional neural networks for raw waveforms.\" 2017 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE, 2017.\n",
    "\n",
    "## Results\n",
    "Through these settings below, we're able to yield 77% accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda Backend!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name  | Type   | Params\n",
      "---------------------------------\n",
      "0 | model | CNN_M5 | 26.9 K\n",
      "---------------------------------\n",
      "26.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "26.9 K    Total params\n",
      "0.108     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8873832a28c942f0ad52622e40ae3242"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dcdf0a472f624127b8634348536d6745"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from src.model.cnn_m5 import CNN_M5\n",
    "from src.model.lit_wrapper import LitWrapper\n",
    "from src.speech_command_dataset import SpeechCommandDataset\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} Backend!\")\n",
    "\n",
    "ds = SpeechCommandDataset(batch_size=256, num_workers=4)  #, dl_kwargs={'pin_memory': True})\n",
    "train_dl, val_dl, test_dl = ds.dls()\n",
    "\n",
    "model = LitWrapper(CNN_M5(len(ds.classes)), ds.classes, lr=0.01)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"cnn_m5/\",\n",
    "    max_epochs=1,\n",
    "    limit_val_batches=192,\n",
    "    limit_predict_batches=1,\n",
    "    # profiler='simple'\n",
    "    # fast_dev_run=True\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "# pred = trainer.predict(model, dataloaders=test_dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
