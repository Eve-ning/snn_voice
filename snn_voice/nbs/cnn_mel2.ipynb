{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# M5 Model\n",
    "\n",
    "This notebook **heavily** references the tutorial: *Speech Command Classification with torchaudio*.\n",
    "- [Tutorial](https://pytorch.org/tutorials/intermediate/speech_command_classification_with_torchaudio_tutorial.html)\n",
    "\n",
    "## Derivations\n",
    "We simplified the tutorial by:\n",
    "- Wrapping the PyTorch model in PyTorch-Lightning, abstracting away all low-level nitty-gritty loops\n",
    "- The M5 Model is simplified in code by wrapping common blocks to avoid redundant code: See `cnn_m5.py`\n",
    "- Using PyTorch-Lightning `Trainer`, we limit the number of batches, to make it run quicker\n",
    "\n",
    "## M5 Model Reference\n",
    "[Research Paper](https://arxiv.org/pdf/1610.00087.pdf)\n",
    "Dai, Wei, et al. \"Very deep convolutional neural networks for raw waveforms.\" 2017 IEEE international conference on acoustics, speech and signal processing (ICASSP). IEEE, 2017.\n",
    "\n",
    "## Results\n",
    "Through these settings below, we're able to yield 77% accuracy after 5 epochs, see the TensorBoard for history.\n",
    "The model has not reach states of overfit, instead, was cut short as it takes a long time."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda Backend!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(limit_predict_batches=1)` was configured so 1 batch will be used.\n",
      "\n",
      "  | Name  | Type    | Params\n",
      "----------------------------------\n",
      "0 | model | CNNMel2 | 82.8 K\n",
      "----------------------------------\n",
      "82.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "82.8 K    Total params\n",
      "0.331     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0c6413892d1e466c98cafa584a18a81e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "27fb8999f78a406da5719558c5246d82"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61670ef46600471bb3832be1002cc03d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "\n",
    "from src.dataset.speech_command_dataset import SpeechCommandDataset\n",
    "from src.model.cnn_mel2 import CnnMel2\n",
    "from src.model.lit_wrapper import LitWrapper\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} Backend!\")\n",
    "\n",
    "ds = SpeechCommandDataset(batch_size=64, num_workers=4)  #, dl_kwargs={'pin_memory': True})\n",
    "train_dl, val_dl, test_dl = ds.dls()\n",
    "\n",
    "model = LitWrapper(CnnMel2(len(ds.classes), n_freq=32, n_time=100, fs=25), ds.classes, lr=0.0002)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    default_root_dir=\"cnn_mel2/\",\n",
    "    max_epochs=15,\n",
    "    # limit_train_batches=128,\n",
    "    limit_val_batches=8,\n",
    "    limit_predict_batches=1,\n",
    "    # profiler='simple'\n",
    "    # fast_dev_run=True\n",
    ")\n",
    "\n",
    "trainer.fit(model, train_dataloaders=train_dl, val_dataloaders=val_dl)\n",
    "# pred = trainer.predict(model, dataloaders=test_dl)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
